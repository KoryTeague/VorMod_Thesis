%
% PROJECT: Thesis for ETD, defense
%   TITLE: Approaches to Joint Base Station Selection and Adaptive Slicing in Virtualized Wireless Networks (Working Title)
%  AUTHOR: Kory Teague
% SAVE AS: KT_Thesis.tex
% REVISED: May 10, 2018

\documentclass[12pt,dvips]{report}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}
\setlength{\evensidemargin}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\topmargin}{0in}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0.1in}

% Uncomment for double-spaced document.
%\renewcommand{\baselinestretch}{2}

% \usepackage{epsf}

\usepackage{cite}

\usepackage[pdftex]{graphicx}
\graphicspath{{Figures/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\usepackage{amsmath}
\usepackage{tcolorbox}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{setspace}

%\onehalfspacing
\doublespacing

\newcommand\myeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}

\begin{document}

\thispagestyle{empty}
\pagenumbering{roman}
\begin{center}

% TITLE
{\Large 
Approaches to Joint Base Station Selection and Adaptive Slicing in Virtualized Wireless Networks
}

\vfill

Kory A. Teague

\vfill

Thesis submitted to the Faculty of the \\
Virginia Polytechnic Institute and State University \\
in partial fulfillment of the requirements for the degree of

\vfill

Master of Science \\
in \\
Electrical Engineering

\vfill

Allen B. MacKenzie, Chair \\
Luiz DaSilva \\
R. Michael Buehrer \\
Mohammad J. Abdel-Rahman

\vfill

% Date, location of defense?
June 1, 2018 (TBD)\\
Blacksburg, Virginia

\vfill

Keywords: TBD
\\
Copyright 2018, Kory A. Teague

\end{center}

\pagebreak

\thispagestyle{empty}
\begin{center}

{\large Approaches to Joint Base Station Selection and Adaptive Slicing in Virtualized Wireless Networks}

\vfill

Kory A. Teague

\vfill

(ABSTRACT)

\vfill

\end{center}

\iffalse
The need for concrete examples increases when technology becomes
difficult to explain.  In documentation for computer systems
especially, we see a wide audience of field experts attempting to
comprehend documentation for computer software and hardware of which
they should only require a cursory understanding.  Additionally, as
the pace of the information age quickens we see document authors
struggle for \textit{examplia-concretes} with wide applicability, and
consistently rely on excerpts from Shakespearean literature as a
public-domain source for their various explications.

We predict the twenty-first century will be no different.  Actuarial
studies show explosion in the information industry such that four out
of five persons will be \textit{bona fide} electronic document
authors; many of those will have one or more college degrees.  We
prove through computer simulation \textsc{Machinum Simitatores} that
authors of twenty-first century literature will be affected by these
examples and will include metaphor with Shakespearean source into
their writing with increasing frequency.
\fi

\vfill

% GRANT INFORMATION

This work received support in part from the National Science Foundation via work involved with the Wireless @ Virginia Tech research group.

\iffalse
That this work received support from the Southeastern Universities
Research Association (SURA) ``Monticello Library Project'' is purely
coincidental.
\fi

\pagebreak

% Dedication and Acknowledgments are both optional
% \chapter*{Dedication}
% \chapter*{Acknowledgments}

\tableofcontents
\pagebreak

\listoffigures
\pagebreak

\listoftables
\pagebreak

\pagenumbering{arabic}
\pagestyle{myheadings}

\chapter{Introduction} \label{ch:intro}
% The following line is to allow document to publish while it doesn't have any normal citations.  Remove once actual citations are present. 
\textit{Placeholder to make bibTeX happy: \cite{1421931}}

\textit{Here I introduce the problem I have been working on (BS selection and dynamic slicing within a VWN).  Start the paragraph talking about the increasing demands within the cellular network; IoT devices, trends toward massive demands.  Mention how costs to maintain and increase the capacity of the network with current costs are rising.  Lead into necessary needs for 5G as intended to be implemented over the next two years, and how virtualization is a potential solution to increase capacity while minimizing cost within 5G networks.}

\section{Motivation} \label{sec:motivation}

\textit{Discuss the motivation behind this thesis.  Invoke the idea of virtualization and the problem of generating a virtual network from a subset of resources.}

\section{Review of Trends in Wireless Networking} \label{sec:netreview}

\textit{Discuss the previously existing literature that I have been reading regarding wireless networking trends.  Discuss wireless cellular networks, virtualization and their use in wireless networks.  Likely work discussing the network without borders paradigm that is at the core of the work.}

\section{Review of Optimization Methods} \label{sec:optreview}

\textit{Discuss the previously existing literature that I have been reading with regards to optimization methods.  Discuss optimization and stochastic optimization.  Discuss metaheuristic algorithms, especially genetic algorithms, and how they have been used for and to simplify optimization.}

\iffalse
%\markright{Albert J. Kippleby \hfill Chapter 1. Introduction \hfill}

William Shakespeare has profoundly affected the field of literature
worldwide \cite{1421931}.  In the United States there was a surge of Shakespearean
literature starting in the 1960s, with the opening of the Montgomery
Shakespearean festival and continuing into the present ...
\pagebreak

%%%%%%%%%%%%%%%%%
%
% Include an EPS figure with this command:
%   \epsffile{filename.eps}
%

%%%%%%%%%%%%%%%%
%
% Do tables like this:

 \begin{table}
 \caption{The Graduate School wants captions above the tables.}
\begin{center}
 \begin{tabular}{ccc}
 x & 1 & 2 \\ \hline
 1 & 1 & 2 \\
 2 & 2 & 4 \\ \hline
 \end{tabular}
\end{center}
 \end{table}
\fi

\pagebreak
\chapter{VNB Model} \label{ch:vnbmodel}

\textit{Begin breaking down the model used as the basis for the work.  Start with a lead in, then start defining the model in the first subsection.  Expound on some of the definitions and descriptions that I moved past in the conference paper (perhaps describing the SSLT model more fully).  Make sure that the definitions and work are generalized for writing about a constructed VWN (or constructed VWNs, depending on the terminology I intend to use) for multiple RPs and SPs.}

\section{Network Area Definitions} \label{sec:networkdefs}

\textit{Lay out the how the network and area is structured here.  Define the SSLT demand field.  This is effectively section 2 of my previous conference paper.}

We consider a geographical area of width $X$ (m) and length $Y$ (m) that contains a set $\mathcal{S} \myeq \left\{1,\, 2,\, \ldots,\, S\right\}$ of BSs available to be leased to the VNB by a set of $\mathcal{N} \myeq \left\{1,\, 2,\, \ldots,\, N\right\}$ RPs.  The rate capacity of BS $s \in \mathcal{S}$ is denoted by $r_s$, its cost is denoted by $c_s$, and its coverage radius is denoted by $b_s$.

A Service Provider (SP) seeking a virtualized wireless network from the VNB is assumed to know the distribution of traffic demand within the region the VWN would cover.  It has been shown that a log-normal distribution or a mixture of log-normal distributions can approximate traffic demand in real-world cellular networks \cite{686105, 5936263}.  It has also been shown that traffic distribution is spatially correlated \cite{5936263, eigenplaces}.  We model the spatial traffic demand of a single SP using a similar, continuous form of the SSLT (Scalable, Spatially-correlated, and Log-normally distributed Traffic) model as proposed by Lee, Zhou, and Niu \cite{6554749}.

To generate this spatial distribution over the area of consideration, an initial Gaussian field, $\rho^G = \rho^G\left(x,\, y\right),\, x \in \left[0,\, X\right],\, y \in \left[0,\, Y\right]$, is generated by
\begin{equation}
\rho^G\left(x,\, y\right)=\frac{1}{L} \; \sum_{l=1}^L \cos\left(i_lx+\phi_l\right) \; \cos\left(j_ly+\psi_l\right)
\end{equation} \label{eq:rhoG}
\noindent where $\mathcal{L} \myeq \left\{1,\, 2,\, \ldots,\, L\right\}$ is a set of the products of two cosines with angular frequencies $i_l,\, j_l\, \sim \mathcal{U}\left(0,\, \omega_{\max}\right),\, l \in \mathcal{L}$ and phases $\phi_l,\, \psi_l\, \sim \mathcal{U}\left(0,\, 2\pi\right),\, l \in \mathcal{L}$.  As $L$ increases, $\rho^G$ approaches a Gaussian random field with a spatial autocorrelation dependent on $\omega_{\max}$ according to the central limit theorem.

The approximate Gaussian distribution $\rho^G$ is then normalized to a standard normal distribution.  The final log-normal distribution, $\rho = \rho\left(x,\, y\right), x \in [0,\, X], y \in [0,\, Y]$, is determined by assigning location and scale parameters
\begin{equation}
\rho\left(x,\, y\right) = \exp\left(\frac{\sigma}{\sqrt{\text{Var}\left(\rho^G\right)}} \; \rho^G\left(x,\, y\right)+\mu\right)
\end{equation} \label{eq:rhoLN}
\noindent where $\text{Var}\left(\rho^G\right)$ is the variance of $\rho^G$.

$\rho\left(x,\, y\right)$ can be sampled over the space into individual pixels as per Lee with each pixel's value indicating the number of homogeneous demand points within the pixel \cite{6554749}.  In contrast, we allow $\rho\left(x,\, y\right)$ to provide a continuous, spatially-correlated log-normal distribution depicting the demand density over the region for the SP.

Let $\mathcal{M} \myeq \{1,\, 2,\, \ldots,\, M\}$ be the set of the SP's demand points seeking to connect to the VWN; the value of total traffic demand at each point is denoted by $d_m$.  Further, let $u_{ms} \in [0,\, 1],\, m \in \mathcal{M},\, s \in \mathcal{S}$, represent the normalized capacity (with respect to $r_s$) of BS $s$ at point $m$, i.e., the normalized maximum rate that a user can receive at point $m$ from BS $s$.  $u_{ms} = 0$ when $m$ is outside the coverage area of $s$ and $u_{ms} = 1$ when $m$ is within a small distance of $s$.  The specific position of the points in $\mathcal{M}$, and therefore the values of $u_{ms}$, is determined via a non-stationary 2D Poisson point process (PPP) with $M$ points using the demand field, $\rho$, as the spatial intensity function.  To generate this non-stationary PPP, we use an acceptance-rejection method.  Each point of a stationary PPP with an intensity of $\rho_{\max} = \max_i\rho\left(x_i,\, y_i\right)$ is retained with probability $\frac{\rho\,\left(x_i,\, y_i\right)}{\rho_{\max}}$, where $x_i$ and $y_i$ are the x- and y-coordinates of the $i^{th}$ point of the stationary PPP.

We assume that a BS $s \in \mathcal{S}$ can be allocated between multiple demand points, and $\delta_{ms} \in [0,\, r_s],\, m \in \mathcal{M},\, s \in \mathcal{S}$, represents the rate of BS $s$ that is allocated to point $m$.

Throughout this paper, stochastic variables will be differentiated from deterministic variables with a tilde ($\sim$) placed above the symbol.

\section{Stochastic Optimization} \label{sec:stochopt}

\textit{Now the that model, area, and definitions are defined, proceed to use those terms and define the overall generalized stochastic optimization problem.  This is effectively section 3 (a) of my conference paper, but with, perhaps, a little more focus.}

We formulate the presented problem as a two-stage stochastic optimization problem.  We introduce $z_s, s \in \mathcal{S}$ as a binary decision variable defined as
\[ z_s \myeq
	\begin{cases}
		1,& \text{if BS $s$ is selected for the created VWN,}\\
		0,& \text{otherwise.}
	\end{cases}
\]

To balance the interest of maximizing demand satisfaction against minimizing cost, we introduce the positive real number $\alpha$ as a weighting coefficient between the two stages.

\vspace{3mm}
\begin{tcolorbox}[title = Problem 1 (Two-Stage Stochastic Optimization Problem)]
\begin{align}
& \underset{\left\{z_s,\, s \in \mathcal{S}\right\}}{\text{minimize}} \left\{ \sum_{s \in \mathcal{S}} c_s \; z_s + \alpha \mathbb{E}\left[ h\left( z,\, u \right) \right] \right\} \label{eq:P1S1}\\
& \text{subject to:}  \nonumber \\
& \hspace{0.4in} z_s \in \{0, 1\}, \forall s \in \mathcal{S} \label{eq:P1S1C1}
\end{align}
where $h(z, u)$ is the optimal value of the second-stage problem, which is given by:
\begin{align}
& \underset{\left\{\substack{\delta_{ms}, m \in \mathcal{M}, s \in \mathcal{S}}\right\}}{\mathrm{minimize}} \left\{ - \sum_{m \in \mathcal{M}} \sum_{s \in \mathcal{S}} \delta_{ms} \; \tilde{u}_{ms} \right\} \label{eq:P1S2}\\
& \text{subject to:}  \nonumber \\
& \hspace{0.4in} z_s = \mathbbm{1}_{\left\{\sum_{m \in \mathcal{M}} \delta_{ms} > 0\right\}}, \forall s \in \mathcal{S} \label{eq:P1S2C1}\\
& \hspace{0.4in} \sum_{s \in \mathcal{S}} \delta_{ms} \; \tilde{u}_{ms} \leq d_m, \forall m \in \mathcal{M} \label{eq:P1S2C2}\\
& \hspace{0.4in} \sum_{m \in \mathcal{M}} \delta_{ms} \leq r_s, \forall s \in \mathcal{S}. \label{eq:P1S2C3}
\end{align}
\end{tcolorbox}

The first stage objective function (\ref{eq:P1S1}) minimizes the total cost of the selected network with respect to that network's ability to satisfy the demand contained within the region.  The second stage objective function (\ref{eq:P1S2}) maximizes demand satisfaction by maximizing the total demand allocated to the resources comprising the network, as specified by $\delta_{ms}$ as the decision variable of the second stage.

Constraints (\ref{eq:P1S1C1}), (\ref{eq:P1S2C1}), and (\ref{eq:P1S2C3}) implement the defined ranges and values of the decision variables $z_s$ and $\delta_{ms}$, with (\ref{eq:P1S2C1}) ensuring that demand is allocated only to selected resources.  For constraint (\ref{eq:P1S2C1}), $\mathbbm{1}_{\{*\}}$ is defined by
\[ \mathbbm{1}_{\{*\}} \myeq
	\begin{cases}
		1,& \text{if condition $\{*\}$ is true,}\\
		0,& \text{otherwise}.
	\end{cases}
\]

Constraint (\ref{eq:P1S2C2}) ensures a demand point $m \in \mathcal{M}$ is not allocated more resources than it demands.

\pagebreak
\chapter{Approximation Approaches} \label{ch:approaches}

\textit{In this chapter, I work on defining the approximation approaches used in my work.  Lead in to discussing the need to approximate the stochastic optimization problem from section \ref{sec:stochopt} to adequately solve my work, then introduce the two approaches I used to approximate the optimization problem: the DEP/its sampling/generalized post-selection slicing and the genetic algorithm as a selection method.}

\section{Deterministic Equivalent Program} \label{sec:dep}

\textit{Introduce the idea of a DEP as an approach for solving the original stochastic problem.  Present the solved problem here in the form of the true deterministic equivalent program - as in, it is actually an equivalent to the original stochastic problem - with all the necessary expansions and additional variables.  Focus on how this formulation no longer includes any stochastic variables and is purely deterministic.  Mention that the trade off is that the deterministic variables are part of a infinitely large set of potential scenarios.}

In order to solve the two-stage stochastic optimization formulation (Problem 1), we need to convert it to a deterministic equivalent program (DEP) that does not contain any stochastic variables (only deterministic variables) \cite{stochprogramming}.

Let $\Omega$ be defined as the sample space, i.e., the set of all scenarios.  Let $\hat{\Omega} \myeq \{1,\, 2,\, \ldots,\, O\}$ be a discrete set containing sampled scenarios.  The probability a given scenario $\omega \in \hat{\Omega}$ occurs is denoted by $p^{(\omega)},\, \omega \in \hat{\Omega}$, where $\sum_{\omega \in \hat{\Omega}} p^{(\omega)} = 1$.  Variables that are dependent on the scenario are shown with a superscript ($\omega$) with the specific scenario it is dependent on indicated by $\omega$.

\vspace{3mm}
\begin{tcolorbox}[title = Problem 2 (Deterministic Equivalent Program of Problem 1)]
\begin{align}
& \underset{\left\{ \substack{
	z_s,\, \delta_{ms}^{(\omega)},\\
	s \in \mathcal{S},\, m \in \mathcal{M},\\
	\omega \in \hat{\Omega}} \right\}} {\text{minimize}}
\Biggl\{ \sum_{s \in \mathcal{S}} c_s \; z_s - \nonumber \\
& \hspace{0.4in} \alpha \sum_{\omega \in \Omega} p^{(\omega)} \left( \sum_{m \in \mathcal{M}} \sum_{s \in \mathcal{S}} \delta_{ms}^{(\omega)} \; u_{ms}^{(\omega)} \right) \Biggr\} \label{eq:P2}\\
& \text{subject to:}  \nonumber \\
& \hspace{0.4in} \sum_{s \in \mathcal{S}} \delta_{ms}^{(\omega)} \; u_{ms}^{(\omega)} \leq d_m,\, \forall m \in \mathcal{M},\, \forall \omega \in \hat{\Omega} \label{eq:P2C1}\\
& \hspace{0.4in} \sum_{m \in \mathcal{M}} \delta_{ms}^{(\omega)} \leq r_s \; z_s,\, \forall s \in \mathcal{S},\, \forall \omega \in \hat{\Omega} \label{eq:P2C2}\\
& \hspace{0.4in} z_s \in \{0,\, 1\},\, \forall s \in \mathcal{S}. \label{eq:P2C3}
\end{align}
\end{tcolorbox}

The objective function (\ref{eq:P2}) combines both objective functions (\ref{eq:P1S1}) and (\ref{eq:P1S2}) of the initial formulation into a deterministic form.  Constraints (\ref{eq:P2C1}) and (\ref{eq:P2C2})	ensure demand is not overallocated and is only allocated to selected resources and within capacity for all scenarios.

Problem 2 provides an equivalent deterministic form of Problem 1 for the (finite) sampled state space, $\hat{\Omega}$, containing $O$ scenarios.  With sufficiently large $O$, $\hat{\Omega}$ approaches a tight approximation of the original sample space.  Within each scenario $\omega \in \hat{\Omega}$, the SSLT demand field $\rho$ is sampled to provide a set of $M$ discrete demand points.  Each sampling of $\rho$ is generated by creating a non-stationary 2D PPP with $M$ points as described in Section \ref{sec:model}.

\subsection{Sampling Approaches} \label{subsec:dep_sampling}

\textit{As the infinitely large set of scenarios renders the problem unable to be solved, it needs to be sampled into a finite set to be solved.  Present the structure and nomenclature used to imply a sampled set of scenarios, and describe the structure of how the scenarios are sampled into a truncated set.  Might be worth mentioning that there are other methods that might be better for sampling beyond the completely random sampling approach I am using.  Worth consideration?}

\subsubsection{Sample Average Approximation} \label{subsubsec:dep_sampling_saa}

\textit{At what point is the sampling enough?  As the set of scenarios considered within the sampled DEP increases, it more closely compares to the original DEP and the stochastic optimization problem, but it also becomes increasingly difficult to solve as the number of scenarios considered increases.  So, it is beneficial to understand that a certain known number of scenarios provides a reasonably tight - what does reasonable mean? - solution to the original DEP to avoid being unnecessarily computationally expensive to solve.  Finding this minimum necessary number of scenarios can be done via a sample average approximation (SAA) analysis, which should not be too complicated to do.}

\subsection{Adaptive Slicing} \label{subsec:dep_slicing}

\textit{Now that we have a (close) approximation to the DEP and the original stochastic optimization problem, we have a method for deriving the minimum cost BS selection and adaptive slicing for the desired VWN.  However, this selection is overly time consuming to constantly run, and the BSs selected for the VWN(s) by the VNB are fairly constant, so all that is needed is to dynamically (read: adaptively) slice the selected BSs to the various SPs.  To do this, we simplify the sampled DEP such that it has only one scenario - ostensibly, the current scenario in time - and the BSs selected set to be a constant rather than a decision variable.  The resulting problem is a single stage linear program that is much simpler to solve.  This is used to adaptively slice resources to the demand.}

After the solution to the sampled DEP of Section \ref{subsec:dep} has been found, the VNB has determined the joint BS selection that forms the VWN and a proposed resource slicing of considered possible scenarios, $\hat{\Omega}$, that allocates the resources to the SP's demand points.  Since $O$ is not infinite, any given scenario present in the formed VWN is unlikely to be an element of $\hat{\Omega}$.  Further, as demand points move between BSs or enter or exit the VWN, a new scenario $\omega \notin \hat{\Omega}$ is formed.  The VWN must adapt its resource slicing to these new demand points to maintain maximal demand satisfaction.  With the VWN built, the joint BS selection, $z_s$, becomes a constant of the network, simplifying Problem 2 to a single-stage optimization problem.

\vspace{3mm}
\begin{tcolorbox}[title = Problem 3 (Deterministic Adaptive Slicing)]
\begin{align}
& \underset{\left\{ \substack{
	\delta_{ms},\,	s \in \mathcal{S},\, m \in \mathcal{M}} \right\}} {\text{maximize}}
\left\{ \sum_{m \in \mathcal{M}} \sum_{s \in \mathcal{S}} \delta_{ms} \; u_{ms} \right\} \label{eq:P3}\\
& \text{subject to:}  \nonumber \\
& \hspace{0.4in} \sum_{s \in \mathcal{S}} \delta_{ms} \; u_{ms} \leq d_m,\, \forall m \in \mathcal{M} \label{eq:P3C1}\\
& \hspace{0.4in} \sum_{m \in \mathcal{M}} \delta_{ms} \leq r_s \; z_s,\, \forall s \in \mathcal{S}. \label{eq:P3C2}
\end{align}
\end{tcolorbox}

It is worth noting that Problem 3 is more tractable than Problem 2 as it only contains the single continuous decision variable for resource slicing, simplifying the objective function (\ref{eq:P3}) and constraint (\ref{eq:P3C2}) from a mixed integer linear program to a linear programming problem.

\section{Genetic Algorithm} \label{sec:ga}

\textit{Now that the first approach - DEP and its sampling - has been tackled, and the necessary tool to evaluate it has been derived from it - the simplified adaptive slicing program - move on to the genetic algorithm approach for approximating the BS selection process.  Discuss the core algorithm of a genetic algorithm, then the various approaches that I used in its process (e.g., binary chromosomes, elitism, uniqueness, uniform crossover, bitwise mutation).}

The Problem 2 formulation becomes intractable as $O$, $S$, or $M$ increases.  Most importantly, the accuracy of the sampled DEP is directly dependent on the size of $\hat{\Omega}$, $O$, directly causing a trade off between the accuracy of the sampled DEP and its computability in a reasonable amount of time.  In this subsection, we reformulate the problem of joint BS selection for the VWN as a genetic algorithm, circumventing the need to discretize demand or to establish $\hat{\Omega}$, thereby simplifying the original problem into a more scalable form.

A genetic algorithm is an iterative metaheuristic in which an approximate solution to a given optimization problem is arrived at via a series of progressive generations.  Each generation contains a number of candidate solutions, called individuals, each of which is defined by a chromosome.  During a given generation, a fitness heuristic is assessed for each individual based on its chromosome.  Then individuals are selected at random, with more fit individuals being selected with higher probability.  Pairs of selected individuals will crossover with probability $p_\text{xov}$, a process similar to genetic recombination in biology.  The resulting chromosomes then have probability $p_\text{mut}$ to mutate, altering the chromosome slightly.  Once enough new individual chromosomes have been selected and possibly undergone crossover and mutation, this set of new individuals, called children, forms the next generation to repeat the process.  %(\textcolor{blue}{\textit{Trim paragraph and cite someone else?}})

For the genetic algorithm, $\rho$ is not sampled for discrete demand points.  Instead, we assume that all demand over the region is allocated to the closest resource.  The subset of $\mathcal{S}$, $\mathcal{S}'$, that is selected for a given possible VWN forms a Voronoi tessellation from the point locations of the selected resources.  The total demand allocated to a selected resource $s \in \mathcal{S}' \subseteq \mathcal{S}$ is $\iint_{V_s} \rho\left(x,\, y\right) \,dx \,dy$, where $V_s$ is the region bounded by the cell of resource \textit{s} in the Voronoi tessellation.  If the total demand allocated to \textit{s} exceeds $r_s$, \textit{s} is considered to be \textit{overcapacity}.  If $V_s$ is not wholly contained within the coverage area of resource \textit{s}, \textit{s} is considered to be \textit{overcoverage}.

Let $\mathcal{G} \myeq \left\{1,\, 2,\, \ldots,\, G\right\}$ be the set of generations used in the genetic algorithm and $\mathcal{I}_g \myeq \left\{1,\, 2,\, \ldots,\, I\right\}, g \in \mathcal{G}$ be the set of individuals within generation \textit{g}.  Each individual $i \in \mathcal{I}_{g \in \mathcal{G}}$ has a binary chromosome $z^{\{ig\}}$ of length \textit{S}.  $z_s^{\{ig\}}, s \in \mathcal{S}$, denoting each individual bit of the chromosome, is defined as follows:
\[ z_s^{\{ig\}} =
	\begin{cases}
		1,& \text{if BS $s$ is selected for the VWN for}\\
		& \hspace{0.4in} \text{individual $i$ in generation $g$,}\\
		0,& \text{otherwise}
	\end{cases}
\]

The fitness heuristic of each individual chromosome, $z^{\{ig\}}$, is assessed as the reciprocal of the chromosome's cost, which is defined as

\begin{equation} \label{eq:GAFit}
\text{fitness}\left(z^{\{ig\}}\right) = \frac{1}{\text{cost}\left(z^{\{ig\}}\right)}
\end{equation}
\vspace{0.2in}
\begin{equation}
\nonumber
\end{equation}
%\vspace{0.01in}
\begin{multline} \label{eq:GACost}
\text{cost}\left(z^{\{ig\}}\right) = \sum_{s \in \mathcal{S}} \Biggl( c_s \; z_s^{\{ig\}} + c_\text{cov} \; \mathbbm{1}_{\left\{ V_s \not\subseteq R_s \right\}} + \\ \left(c_\text{cap}^g - 1\right) \; \max\left( 0,\, \iint_{R_s} \rho\left(x,\, y\right)\, dx\, dy - r_s \right) \Biggr)
\end{multline}

\noindent where $R_s$ is the coverage area region of resource $s \in \mathcal{S}$.

The cost function (\ref{eq:GACost}) indicates cost increases not only based on the cost of the resources selected, but also with imperfection costs $c_\text{cov}$ and $c_\text{cap}$, the costs of a selected resource being overcoverage or overcapacity, respectively.  The overcapacity cost grows with each successive generation.  For early generations, this allows for imperfect solutions to temporarily exist to seed later generations and improve diversity to increase the probability of finding a better final approximate solution.

Elitism is used, where the \textit{n} most fit individuals of a given generation are automatically selected without crossover or mutation to be the first children of the next generation.  Selection occurs via the roulette wheel selection method.  Every individual $i$ of a given generation $g$ has a probability of being selected given by
\[
\frac{\text{fitness}\left( z^{\{ig\}} \right)}{\sum_{i \in \mathcal{I}} \text{fitness}\left( z^{\{ig\}} \right)}
\]

When crossover is performed on selected individuals, it is via the uniform crossover method with a mixing ratio of 0.5.  That is, if two selected parent individuals crossover, each equivalent bit in the parents will swap with a probability of 50\%.  Mutation occurs on a bit-by-bit level, with each bit mutating (i.e., flipping) with probability $\frac{1}{S}$.  The uniqueness property is then enforced on the resulting children to ensure diversity; if a child chromosome is identical to another child chromosome in the next generation, the child is discarded and a new child generated, ensuring that each individual of any given generation is unique within that generation.

The genetic algorithm iterates for a number of generations $G$.  If the genetic algorithm settles on a single individual for a number of continuous generations, $G_\text{halt}$, it will halt and present that individual's chromosome as the final approximate solution for $z_s$.  Otherwise, the chromosome of the fittest individual of generation $G$ determines $z_s$.

The genetic algorithm only determines an approximate solution to the BS selection forming the VWN, informing the VNB of which BSs to obtain from the RPs.  With this selection, $z_s$, the SP's demand points can be dynamically allocated resource slices as described by Problem 3 in Section \ref{subsec:dep_slicing}.

\pagebreak
\chapter{Testing and Simulations} \label{ch:testsim}

\textit{In this chapter I will be introducing four different cases to test the provided approximation approaches.  The first will be the test case used in my conference paper (one SP, with homogeneous resources).  The second will be an expansion of the test case used in my conference paper, but with heterogeneous resources.  The third will extend to service multiple similar cellular SPs.  The fourth will extend to a case with multiple SPs with various, specialized demands.}

\section{VWN Construction for a Single SP} \label{sec:onesp}

\textit{Lead into the first two cases, which test the approaches while using a single SP.}

\subsection{Case I: Homogeneous Urban Cellular Network} \label{subsec:onesp_homres}

\textit{Basically as presented in my conference paper.  One SP, homogeneous resources within the RPs.  Might need to use a new data set, though, with a larger data set.}

\subsection{Case II: Impact of Heterogeneous Resources} \label{subsec:onesp_hetres}

\textit{Same as Case I, but with heterogeneous resources within the RPs.  Need to understand how this changes the approaches.}

\section{VWN Construction for Multiple SPs} \label{sec:mulsp}

\textit{Lead into the second two cases (should I have more?), which test using multiple SPs to satisfy from the same set of resources.}

\subsection{Case III: Two Similar Urban Cellular Networks} \label{subsec:mulsp_sim}

\textit{First consider a case with two SPs with similar demands.  Overlapping cellular networks.  Could see how the approaches behave while two SPs partially overlap.}

\subsubsection{Homogeneous Resources} \label{subsubsec:mulsp_sim_homres}

\textit{If it appears that the difference between Case I and Case II (sections \ref{subsec:onesp_homres} and \ref{subsec:onesp_hetres}) is worth further consideration, then analyze here with homogeneous resources.  Otherwise, a single comparison should be sufficient.}

\subsubsection{Heterogeneous Resources} \label{subsubsec:mulsp_sim_hetres}

\textit{As for the previous subsubsection (\ref{subsubsec:mulsp_sim_homres}), but consider with heterogeneous resources.}

\subsection{Case IV: SPs with Specialized Demands} \label{subsec:mulsp_spec}

\textit{This is the major case that is the extension of my work.  Case I (\ref{subsec:onesp_homres}) analyzed what happens with a single SP, Case II (\ref{subsec:onesp_hetres}) expanded that to heterogeneous resources, and Case III (\ref{subsec:mulsp_sim}) added an additional similar SP, but Case IV considers when there are several SPs and with their own considerations and unique demands.  Need to consider what these SPs look like.  One would be a cellular network like in Case I (moderate to high number of users, moderate demand).  Another could be a streaming service (few users, high individual demand).  Another an emergency service (very low number of users and demand, but requiring virtually 100\% demand satisfaction - see note below).  What other SPs should I consider?}

\textit{\textbf{Note}: I need to consider how to accurately label demand satisfaction within the approaches.  In effect, this would be controlled by $\alpha$ for the (sampled) DEP and controlled by $\beta$ or some such for the genetic algorithm.  I should investigate this at some point of the thesis, probably within their appropriate sections in chapter \ref{ch:approaches} (DEP: \ref{sec:dep} and GA: \ref{sec:ga}).}

\subsubsection{Homogeneous Resources} \label{subsubsec:mulsp_spec_homres}

\textit{As for Case III (\ref{subsec:mulsp_sim}), if a considerable difference was detected between Cases I and II (\ref{subsec:onesp_homres} and \ref{subsec:onesp_hetres}), consider analyzing the case with homogeneous resources and}

\subsubsection{Heterogeneous Resources} \label{subsubsec:mulsp_spec_hetres}

\textit{also with heterogeneous resources.}


\pagebreak
\chapter{Conclusions} \label{ch:conc}

\textit{Consider conclusions of my work.  I don't think this chapter would be long, but condense my findings into some coherent thoughts, and redirect to what they are.  Also expound on some of the further work that my research could be expanded to (e.g., further use cases investigating my approaches, use of (meta)heuristics other than a genetic algorithm to approximate the optimization problem, improve the basic capacity function used in my optimization model).}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% If you are using BibTeX, uncomment the following:
%\thebibliography
%
% Otherwise, uncomment the following:
% \chapter*{Bibliography}

% \appendix

% In LaTeX, each appendix is a "chapter"
% \chapter{Program Source}



\bibliography{KT_Thesis}
\bibliographystyle{IEEEtran}

\end{document}